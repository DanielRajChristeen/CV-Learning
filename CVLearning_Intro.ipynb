{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM1naO6kOFG/yv/FUNfoGA2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DanielRajChristeen/CV-Learning/blob/main/CVLearning_Intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Computer Vision Learning - Part 1**\n",
        "\n"
      ],
      "metadata": {
        "id": "xAqckKWFpqDY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  **What Is Computer Vision, Fundamentally?**\n",
        "\n",
        "###**Definition:**\n",
        "\n",
        "Computer Vision (CV) is the field that enables computers to *perceive, interpret, and understand visual data* (images and videos) the way humans do — or, in some cases, even better.\n",
        "\n",
        "It’s a subdomain of Artificial Intelligence (AI) and overlaps with image processing, pattern recognition, and deep learning.\n",
        "\n",
        "### **Real-world perspective:**\n",
        "\n",
        "Every CV task boils down to **translating pixels → meaning**.\n",
        "\n",
        "* Pixels are just numbers (intensity values).\n",
        "* CV pipelines are about turning those numbers into **semantic understanding** — “This is a car,” “That’s a stop sign,” “The person is walking.”\n"
      ],
      "metadata": {
        "id": "td7rn1zRtEnP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **How a Computer Sees an Image**\n",
        "\n",
        "Think of an image as a **matrix**.\n",
        "\n",
        "### Example:\n",
        "\n",
        "A grayscale image (black & white) is just a 2D matrix:\n",
        "\n",
        "```\n",
        "[\n",
        " [0,  30, 255],\n",
        " [45, 120, 200],\n",
        " [60,  90, 130]\n",
        "]\n",
        "```\n",
        "\n",
        "Each value = brightness of a pixel\n",
        "(0 = black, 255 = white)\n",
        "\n",
        "A **color image** is a 3D matrix (height × width × channels):\n",
        "\n",
        "* Channels: Red, Green, Blue (RGB)\n",
        "* Each pixel = [R, G, B] value triplet\n",
        "\n",
        "So when you look at a photo, a computer only sees something like:\n",
        "\n",
        "```\n",
        "[\n",
        " [[120, 33, 90], [119, 35, 87], ...],\n",
        " [[121, 36, 92], [122, 38, 89], ...]\n",
        "]\n",
        "```\n",
        "\n",
        "That’s it — no “cat,” no “face,” no “car.”\n",
        "Just numbers that vary in patterns.\n"
      ],
      "metadata": {
        "id": "b0N_VZzLtLcg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **The Four Core Stages of Vision Systems**\n",
        "\n",
        "Everything we do in CV — from a barcode reader to autonomous driving — fits roughly into these four stages:\n",
        "\n",
        "| Stage                  | Function                                      | Example                                   |\n",
        "| ---------------------- | --------------------------------------------- | ----------------------------------------- |\n",
        "| 1️⃣ Image Acquisition  | Capture or load data (camera, video, sensors) | Webcam frames, satellite images           |\n",
        "| 2️⃣ Preprocessing      | Clean and normalize pixels                    | Denoising, resizing, contrast enhancement |\n",
        "| 3️⃣ Feature Extraction | Identify patterns or structures               | Edges, corners, colors, motion, textures  |\n",
        "| 4️⃣ Interpretation     | Assign meaning                                | Classification, detection, tracking       |\n",
        "\n"
      ],
      "metadata": {
        "id": "NnKoCE-rw24l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Traditional CV vs. Deep Learning CV**\n",
        "\n",
        "| Traditional CV                                              | Deep Learning CV                      |\n",
        "| ----------------------------------------------------------- | ------------------------------------- |\n",
        "| Hand-engineered features (edges, corners, color histograms) | Learns features automatically         |\n",
        "| Used algorithms like SIFT, SURF, HOG                        | Uses neural networks (CNNs, ViTs)     |\n",
        "| Works well for simple tasks                                 | Scales to complex perception problems |\n",
        "| Requires domain intuition                                   | Requires data & compute power         |\n",
        "\n",
        "Both coexist today.\n",
        "A modern CV engineer understands *both sides* — because traditional methods are still useful for **preprocessing, pipelines, or low-power systems**, while deep learning dominates **semantic tasks**.\n",
        "\n"
      ],
      "metadata": {
        "id": "AZTR_zZXxBj6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **The Mathematical Backbone**\n",
        "\n",
        "Let’s ground this in **linear algebra and signal processing** — the true backbone.\n",
        "\n",
        "### **An image is a signal.**\n",
        "\n",
        "In signal processing:\n",
        "\n",
        "* A 1D signal = audio waveform\n",
        "* A 2D signal = image\n",
        "* A 3D signal = video or volumetric data\n",
        "\n",
        "So image operations (like blurring or sharpening) are just **mathematical filters** that modify pixel intensity values.\n",
        "\n",
        "#### **Example — Image Blur**\n",
        "\n",
        "Mathematically:\n",
        "\n",
        "> Each output pixel = weighted average of its neighbors.\n",
        "\n",
        "That’s a **convolution operation** (the “Conv” in CNNs).\n",
        "\n",
        "If you apply a matrix called a **kernel** over an image, you get effects like edge detection, sharpening, or smoothing.\n",
        "\n",
        "This is why understanding convolution at a matrix level is *step one* before touching deep learning."
      ],
      "metadata": {
        "id": "WJ9wCx2pxHhK"
      }
    }
  ]
}